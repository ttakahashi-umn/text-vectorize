{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Text Vectorization Sample",
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T08:59:10.805686Z",
     "start_time": "2024-10-05T08:59:10.803131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from transformers import BertJapaneseTokenizer, BertModel"
   ],
   "id": "7df9140457caed5e",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Load tokenizer and BERT large model\n",
    "\n",
    "In this case, we need an text-vectorization output with 1024 tensors. Therefore, I chose \"bert-large-uncased\". At the same time, we need to vectorize Japanese text and I chose \"cl-tohoku/bert-large-japanese\"."
   ],
   "id": "2e44cfe2f556cba1"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-05T09:19:15.526895Z",
     "start_time": "2024-10-05T09:18:53.725515Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. BERTのトークナイザーとモデルをロード\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-large-japanese')\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cbd3b71c4c1a441591546d80d43bcab2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28e845b3e11f40b1b469eb1170dd9cef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Tokenize text\n",
    "\n",
    "output tensor type is PyTorch."
   ],
   "id": "62a8c026dc794d85"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T09:19:20.370782Z",
     "start_time": "2024-10-05T09:19:20.358509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. テキストのトークナイズ\n",
    "input_text = \"こんにちは、元気ですか？\"  # 入力文\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")  # PyTorchのテンソル形式でトークナイズ\n"
   ],
   "id": "e65e58a1b7e04493",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Vectorize the input text with the preloaded model",
   "id": "ed513bfc233ca6f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T09:19:25.325889Z",
     "start_time": "2024-10-05T09:19:22.227111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. モデルを使ってエンコーディング（ベクトル化）\n",
    "with torch.no_grad():  # 勾配計算をオフにする\n",
    "    outputs = model(**inputs)\n"
   ],
   "id": "bfc9f7227b662e2e",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output the result",
   "id": "aab22bf60d693447"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T09:19:26.914079Z",
     "start_time": "2024-10-05T09:19:26.887739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. 出力結果\n",
    "# outputs.last_hidden_state: トークンごとのベクトル表現\n",
    "# outputs.pooler_output: 文全体のベクトル表現\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "pooler_output = outputs.pooler_output\n",
    "\n",
    "# トークンごとのベクトル表現の形状を確認（例: 1つの文、10のトークン、1,024次元の埋め込みベクトル）\n",
    "print(\"Last Hidden State Shape:\", last_hidden_state.shape)\n",
    "\n",
    "# 文全体のベクトル表現の形状を確認（例: 1つの文、1,024次元のベクトル）\n",
    "print(\"Pooler Output Shape:\", pooler_output.shape)\n",
    "\n",
    "# 最終的な文のベクトルを出力\n",
    "print(\"Sentence Vector:\", pooler_output)"
   ],
   "id": "bb22c02b6d9678db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last Hidden State Shape: torch.Size([1, 10, 1024])\n",
      "Pooler Output Shape: torch.Size([1, 1024])\n",
      "Sentence Vector: tensor([[-0.9879, -0.8875,  0.8720,  ...,  0.3260,  0.9127, -0.5225]])\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
